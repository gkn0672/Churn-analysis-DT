{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI236 assignment 1 Task1 \n",
    "* Name: Nguyen Gia Khanh\n",
    "* UOWID: 7311217\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read csv file as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"customer_churn_dataset-training-master.csv\")\n",
    "df2 = pd.read_csv(\"customer_churn_dataset-testing-master.csv\")\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identify missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get general info about test dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing value in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = df[df.isnull().any(axis=1)]\n",
    "missing_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In train dataset, row 199295 contains missing values <br>\n",
    "We can safely remove the whole data point because: <br>\n",
    "- This is the only record that has missing value (<5% dataset's size)\n",
    "- It missing all of its attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using z-score normalization for column \"Last Interaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_li = df[\"Last Interaction\"].mean()\n",
    "train_std_li = df[\"Last Interaction\"].std()\n",
    "df[\"LI z-score\"] = (df[\"Last Interaction\"] - train_mean_li)/train_std_li\n",
    "# Swap the values and column names\n",
    "df['Churn'], df['LI z-score']  = df['LI z-score'], df['Churn']\n",
    "df.rename(columns={'Churn': 'LI z-score', 'LI z-score': 'Churn'}, \n",
    "                    inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[\"LI z-score\"].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance of normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LI z-score\"].var()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create five bins for the attribute “Total Spend” such that the bins contain (approximately) equivalent numbers of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = ['Bin1', 'Bin2', 'Bin3', 'Bin4', 'Bin5']\n",
    "df['Total Spend'] = pd.cut(df['Total Spend'], bins=5, labels=bin_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Apply one-hot-encoding to the attribute “Contract Length”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pd.get_dummies(df[\"Contract Length\"]).astype(int)\n",
    "df = pd.concat([df, ohe], axis=1)\n",
    "df = df.drop(columns=[\"Contract Length\"])\n",
    "# Specify the desired column order\n",
    "desired_order = [\n",
    "    'CustomerID', 'Age', 'Gender', 'Tenure', 'Usage Frequency', 'Support Calls',\n",
    "    'Payment Delay', 'Subscription Type', 'Total Spend',\n",
    "    'Last Interaction', 'LI z-score', 'Annual', 'Monthly', 'Quarterly','Churn'\n",
    "]\n",
    "\n",
    "# Reorder the columns in the DataFrame\n",
    "df = df[desired_order]\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define at least one new attribute based on existing attribute, and explain your reason behind your definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute purpose: Support request frequency <br>\n",
    "---\n",
    "Measured by: Support Calls / Tenure <br>\n",
    "---\n",
    "Explanation:<br>\n",
    "<ul>\n",
    "<li> By dividing the total support calls by the customer tenure, we can know how often a customer reach for assistance while using the service.\n",
    "<li> The more often customer requests support, the more frustration they may experience, and this can be a good attribute to measure customer churn.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Support request frequency\"] = df[\"Support Calls\"] / df[\"Tenure\"]\n",
    "df['Churn'], df['Support request frequency']  = df['Support request frequency'], df['Churn']\n",
    "df.rename(columns={'Churn': 'Support request frequency', 'Support request frequency': 'Churn'}, \n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
